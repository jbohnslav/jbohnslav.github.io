[{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17 Original Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780 Source: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer23. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up34.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability891011, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\n\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\n\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17 Original Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780 Source: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer23. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up34.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability891011, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\n\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\n\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17 Original Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780 Source: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer23. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up34.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability891011, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\n\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\n\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17 Original Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780 Source: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer23. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up34.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability891011, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\n\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\n\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17 Original Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780 Source: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer23. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up34.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability891011, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\n\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\n\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17 Original Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780 Source: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer23. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up34.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability891011, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\n\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\n\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17\nOriginal Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\nSource: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer23. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up34.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability891011, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17\nOriginal Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\nSource: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer2 3. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up3 4.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability891011, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17\nOriginal Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\nSource: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer2 3. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up3 4.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability891011, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17\nOriginal Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\nSource: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer2 3. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up3 4.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability8 9 10 11, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! 161718.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP17!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic19. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog17! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm20).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog17, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJeremy Bernstein\u0026rsquo;s \u0026ldquo;Deriving Muon\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17\nOriginal Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\nSource: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer2 3. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up3 4.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability8 9 10 11, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! [^16 ]16 17.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP16!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic18. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog16! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources36:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm19).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog16, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17\nOriginal Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\nSource: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer2 3. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up3 4.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability8 9 10 11, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! [^16 ]16 17.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP16!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic18. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog16! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources3 6:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm19).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog16, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17\nOriginal Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\nSource: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer2 3. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up3 4.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability8 9 10 11, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! [^16 ]16 17.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP16!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic18. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog16! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources3 6:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm19).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog16, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"},{"content":"About the translation This is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found here. The author\u0026rsquo;s tweet about it is here. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\nOriginal Post Author: toothacher17\nOriginal Link: https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\nSource: Zhihu\nCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\nDisclaimer: Former Moonshot “No. 1 hype-man” (some say I’m competing with @Andrew Lu) and long-time Feilai Pavilion fan1—just riding the K2 hype wave.\n1. Concerns About Using the Muon Optimizer It\u0026rsquo;s worth noting that the K2 model released by Moonshot was trained end-to-end using the Muon optimizer2 3. Muon was first proposed by Keller and performed exceptionally well in Speedrun2. It was then picked up by Moonshot, where they made some adjustments and scaled it up3 4.\nIn Moonshot’s early work3 they highlighted Muon’s impressive token-efficiency and even released a Megatron-LM implementation5. Subsequent discussion on X (formerly Twitter) surfaced three recurring concerns:\nExpensive Operations: Muon requires the full parameter matrix for its \u0026ldquo;Normalized Stochasticity\u0026rdquo; (NS) calculation. In the parallel setting of modern LLM training infrastructure, many believe operating on the full parameter matrix is too expensive. Complex Hyperparameter Tuning: Muon requires \u0026ldquo;several sets\u0026rdquo; of different hyperparameter tuning mechanisms, which places higher demands on model tuning. In contrast, self-adaptive optimizers like AdamW seem simpler and more stable to tune. Training Instability: Muon might cause training instability. For instance, Moonshot\u0026rsquo;s own paper3 mentioned a potential issue with the attention max logit. In fact, with the release of K26, it\u0026rsquo;s clear these problems aren\u0026rsquo;t deal-breakers. This blog post will attempt to \u0026ldquo;argue the case\u0026rdquo; for why.\n2. Concern 1: Muon\u0026rsquo;s Infrastructure Scalability First, let\u0026rsquo;s discuss whether operating on Muon\u0026rsquo;s full parameter matrix is truly expensive, and in doing so, fill in a small gap left in the previous paper3.\nTo clarify this, we need to detail Zero-1 sharding. Then, by understanding its implementation and the differences between Chinese and international training clusters (Why international? Because some foreign companies are challenging this on X, essentially because they are flush with cash and have too many GPUs), we can explain why the Moonshot team believes Muon\u0026rsquo;s infra is scalable, while others remain skeptical.\n2.1 Zero-1 Sharding First, some background. In modern LLM training involving large models and large clusters, the Zero-1 optimizer is a standard technique. Frameworks like Megatron-LM, DeepSpeed, and FSDP all have support for it.\nZero-1 technology essentially shards the optimizer states—which consume a lot of GPU memory (e.g., AdamW\u0026rsquo;s exp, exp_square, fp32_master_weights)—across the Data Parallel (DP) group.\nWhen using AdamW, the lifecycle of the Zero-1 Distributed Optimizer is as follows:\nGradient Reduce-Scatter: Perform a reduce_scatter of gradients between DP ranks. It\u0026rsquo;s a reduce_scatter instead of an all_reduce because of the sharding. Each DP rank only needs to ensure the gradients for the local parameters it\u0026rsquo;s responsible for are accurate. Local Parameter Update: Perform the AdamW update calculation for the local parameters. Since AdamW\u0026rsquo;s calculation is element-wise, this step only needs to compute the updates for local parameters. Parameter All-Gather: Perform a parameter all_gather between DP ranks. Because each DP rank only updated a portion of the parameters, an all_gather is needed for all ranks to get the complete, updated set of parameters. Note that steps 1 and 3, while seemingly communication-heavy, can actually be overlapped with the model\u0026rsquo;s forward/backward pass (a very mature technique all major frameworks implement), so there\u0026rsquo;s no need to worry. In step 2, since AdamW is element-wise and the computation per rank decreases as DP size increases, it\u0026rsquo;s highly scalable.\nIn summary, this distributed optimizer technology is very friendly to AdamW. The time cost of the AdamW optimizer is typically less than 1% of the entire global step, basically negligible compared to the forward/backward pass.\nHowever, Muon faces a significant challenge in step 2 because its calculation is not element-wise. Muon requires the full parameter matrix to compute NS, which inevitably introduces additional communication and a larger computational load (running NS on the entire matrix).\nFor Muon to be as scalable as possible, the communication overhead of step 2 needs to be minimal (as it can hardly be hidden), and the additional computation introduced needs to be as small as possible (a single small matrix runs NS quickly, so we should avoid running NS on overly large or numerous matrices per DP rank).\n2.2 The Moonshot Solution Based on Moonshot\u0026rsquo;s open-source work5, it\u0026rsquo;s speculated that their development is based on a version of Megatron-LM that they have since maintained. For Megatron-LM, its early implementation of the Zero-1 optimizer7 is as follows (we\u0026rsquo;ll call it \u0026ldquo;flat-param concat zero-1\u0026rdquo;):\nAs you can see, the approach is to flatten all optimizer states, concatenate them, and then distribute them evenly across the DP group. This allocation method is optimal for GPU memory because there are no duplicate optimizer states. Moreover, this partitioning is highly beneficial for Muon because most of the local parameters remain complete and can be directly used for the NS operation. Only the parameters at the DP boundaries are split across two DP ranks and become incomplete, requiring special handling.\nSpecifically, taking DP0 and DP1 jointly processing Param 1 as an example, if we were to brainstorm solutions, there are several approaches:\nThe \u0026ldquo;Brainless\u0026rdquo; Gather Method: DP0 and DP1 each perform a gather to get the full parameters. Both ranks then perform the full NS calculation. After computation, each rank only updates its local portion of the parameters and discards the rest. The grad_reduce_scatter and params_all_gather of steps 1 and 3 remain unchanged to avoid redesigning the algorithm. Edge Parameter Passing: Each DP rank i sends its edge parameters to DP i-1. DP i-1 is then responsible for the computation on these edge parameters. After calculation, the result is sent back to rank i to update the portion it maintains. This avoids redundant computation, and the communication volume is actually better than the brainless gather method. However, for extreme cases, like a parameter spanning three DP ranks, this requires more complex heuristic arrangements. Heuristic Precision Arrangement: When arranging the distributed optimizer, prevent the DP edge-splitting from happening in the first place. This eliminates any extra communication and computation. The cost is that memory allocation is no longer balanced, and finding the optimal allocation becomes a knapsack problem. Unbalanced memory allocation is obviously unacceptable for infrastructure engineers as it leads to inaccurate memory estimation during training, affecting the parallel allocation strategy. In practice, Moonshot uses the brainless gather method because it is the simplest to implement and covers all edge cases. Crucially, the overhead is small—only parameters that straddle a DP boundary (≈ DP × 2) incur duplicate computation or extra communication. Other parameters, like param0 and param2 in the diagram, are complete and don\u0026rsquo;t require any extra work.\nEmpirically, the actual performance of this communication and computation will be affected by the number of DP ranks and the maximum matrix size in the model. Considering modern MoE architectures (thanks, DeepSeek-V2), a model won\u0026rsquo;t have excessively large matrices because they are all fine-grained experts (and word embedding/lm_head are controlled by AdamW, not Muon). Therefore, in the long run, Muon\u0026rsquo;s scalability has a bright future and is steadily improving.\nSince the cost of the brainless method is already low, the benefits of engineering a more complex solution are minimal, which is likely why \u0026ldquo;Jiang Kernel\u0026rdquo; (a nickname for a key person) didn\u0026rsquo;t have the motivation to pursue it further (though I recall You Jiacheng might have implemented some similar solutions on Speedrun?).\n2.3 Others\u0026rsquo; Concerns However, in the research from some foreign companies, there is a pessimistic bias towards Muon\u0026rsquo;s scalability8 9 10 11, and Moonshot\u0026rsquo;s method5 has been repeatedly criticized. Obviously, it\u0026rsquo;s not that everyone else is an idiot. But based on the analysis in 2.2 and the fact that Moonshot successfully trained K2 at a large scale, Moonshot isn\u0026rsquo;t an idiot either.\nI personally believe the main reason for this conflict is the different implementations of Zero-1, which leads to a large discrepancy in the estimated overhead of Step 2.\nThe mainstream method abroad is called dim-0 sharding Zero-1. For example, the Zero-1 implementation in the mainstream foreign parallel framework, PyTorch FSDP2, is as follows12:\nAnd a newer version of Megatron-LM13 introduced the concept of \u0026ldquo;buckets.\u0026rdquo; The essence of this concept is similar in effect to params dim-0 sharding:\nThese updates are actually a \u0026ldquo;devastating\u0026rdquo; blow to the Muon implementation that preceded Moonshot\u0026rsquo;s work. This type of Zero-1 implementation causes every parameter to be sharded by DP! Whether it\u0026rsquo;s the brainless gather method, the edge-passing method, or the sophisticated arrangement method, all of which are based on \u0026ldquo;flat-param concat zero-1,\u0026rdquo; they are all ruined. Every parameter now requires communication and redundant recalculation, leading to a massive amount of extra overhead, making Muon unacceptable.\n2.4 Long-Term Solution Foreign companies are definitely not stupid. Early parallel designs actually all used flat-param concat zero-114. Later, due to other concerns (mainly that foreign companies have too many GPUs, and flat params are not conducive to overlapping grad_reduce_scatter and params_all_gather), they switched to dim-0 params sharding Zero-1.\nIn the context of mandatory dim-0 params sharding, the Moonshot method is indeed not scalable. But this does not mean Muon is inherently unscalable. New solutions will definitely emerge. In fact, I\u0026rsquo;ve heard that it seems possible, and someone might already be working on it (smirking dog face emoji).\n3. Concern 2: Muon Needs More Hyperparameters Another common complaint is that Muon has several sets of hyperparameters, which is seen as a significant disadvantage compared to AdamW:\nIt requires additional tuning efforts. The need for extra tuning means more mental overhead to find the best model, which isn\u0026rsquo;t a fair comparison to AdamW. If AdamW were also tuned in blocks, it might achieve better results. I personally think this concern stems from a lack of precise understanding of the mathematical properties of the Muon optimizer. To understand Muon, we need to look at it from the perspectives of Standard Parametrization (SP) and Maximal Update Parametrization (µP) to see why multiple sets of parameters need adjustment.\nAdditionally, Muon is designed for matrices2. Non-matrix parameters like word embeddings, lm_head, and rmsnorm_gamma are all updated using AdamW.\n3.1 Standard Parametrization (SP) + Muon Let\u0026rsquo;s first look at Muon under SP. When Moonshot started researching/reproducing (i.e., copying) Keller\u0026rsquo;s Muon in its early days (around January 2024)15, it looked like this (without weight decay and without the various engineering optimizations added by Mr. You, like the zero-1 optimizations):\nAt this stage, there weren\u0026rsquo;t so many outrageous sets of parameters—just one set for AdamW and one for Muon. However, the update RMS (Root Mean Square) of Muon is very different from that of AdamW. In Moonshot\u0026rsquo;s work3, Su Yin provided a derivation:\nThis shows that AdamW\u0026rsquo;s update RMS is empirically around 0.2-0.4, while Muon\u0026rsquo;s is much smaller. If you don\u0026rsquo;t increase Muon\u0026rsquo;s update RMS (the simplest way being a dedicated learning rate), Muon simply won\u0026rsquo;t update effectively, making it an unfair comparison.\nIn the SP setting, if you don\u0026rsquo;t want to tune two sets of parameters, you can directly use Moonshot\u0026rsquo;s work3. By matching the update RMS, it\u0026rsquo;s practically \u0026ldquo;out-of-the-box.\u0026rdquo; You can use a single set of AdamW hyperparameters. There\u0026rsquo;s plenty of work on how to tune AdamW hyperparameters (e.g., the stepfun law). Just copy one and migrate it to Muon using Moonshot\u0026rsquo;s method, and you will likely get good improved loss token efficiency.\nIn fact, the main contribution of Moonshot\u0026rsquo;s work is here: allowing everyone to migrate to Muon in the SP setting without much thought. My superficial understanding is that this is equivalent to the fastest optimization under a matrix Frobenius norm constraint, which effectively controls the update RMS, similar to AdamW. It meets the requirements of SP, but it\u0026rsquo;s not optimal. For Muon, the theoretically optimal method is the fastest optimization under a spectral norm constraint, which we will discuss next.\n3.2 µP Parametrization + Muon The most exciting use of Muon is not SP, but its combination with µP (Maximal Update Parametrization). A series of open-source works have provided very exciting introductions! [^16 ]16 17.\nIn short, Muon is almost an optimizer tailor-made for µP. Unlike using µP + AdamW, which introduces many variance-based assumptions, Muon naturally controls the spectral norm (because NS mathematically clips the max singular values, and the max singular value is the spectral norm by definition). This makes it perfectly suited for the spectral norm control required by high-order µP16!\nLooking at Keller\u0026rsquo;s improvement history on Muon, besides infrastructure optimizations by masters like Mr. You, the main evolution was the introduction of µP ideas by the \u0026ldquo;god-tier\u0026rdquo; Jeremy Bernstein (Jeremy is an author of both µP and the Muon blog, so he\u0026rsquo;s a double-threat).\nAfter introducing ideas similar to µP, the Embedding, LM Head, and Hidden Matrices all got their own control logic18. Although it seems outrageous, it\u0026rsquo;s reasonable when you consider the need to adapt to µP (in fact, adapting AdamW for µP also requires learning rate adjustments for different modules).\nIn particular, look at the adjustment of Muon\u0026rsquo;s update RMS here. Ignore the max(1, x) part for a moment and just look at the sqrt(d_out/d_in) part. This is exactly the same as the derivation in Su Yin\u0026rsquo;s high-order µP blog16! (Though I don\u0026rsquo;t know why the max(1, x) operation was added. With max, it actually reverts to a Frobenius norm-like scaling, doesn\u0026rsquo;t it?)\n4. Concern 3: Muon Training Instabilities In reality, few companies train Muon at truly large scale. Moonshot themselves report only two instability sources3 6:\nWeight decay. The max attention logit problem (addressed by muonclip). Weight decay is easy to understand, while the max attention logit problem involves the muonclip method mentioned in their recent blog6.\nThe max attention logit problem can usually be solved with qknorm, but Moonshot used MLA (Multi-Head Latent Attention) in K2 (I have to say, DeepSeek is ruthless; their model architectures are tried-and-true winners). The results are probably just that good, so there\u0026rsquo;s no need to force innovation when a great technology already exists. MLA adds normalization during compression, but for inference efficiency, the q and k heads aren\u0026rsquo;t materialized, which means you can\u0026rsquo;t perform qk-head normalization.\nTherefore, Moonshot took a different approach and created muonclip (in fact, others have also expressed concerns about the effectiveness of qknorm19).\nI personally find muonclip very elegant! In Su Yin’s high-order MuP blog16, we learn that the spectral norm is smaller than the Frobenius norm:\nAnd the spectral norm is directly tied to the maximum logit size, i.e.\n||x W||₂ ≤ ||x||₂ · ||W||₂\n(where W is a matrix, so ||W||₂ is its spectral norm). The most direct approach is to control the spectral norm. However, the spectral norm is difficult to calculate. So, we can use the inequality relationship between spectral and Frobenius norms and directly clip the Frobenius norm. By doing so, ||xW||_2 will be controlled!\nBut later I had a chance to chat with Su Yin, and he said he didn\u0026rsquo;t think that far ahead, and my understanding might not be right (I was floored). His idea was to directly operate on the fundamental problem. Su Yin mentioned he will be releasing a blog post in the next few days, so keep an eye out for that.\n5. Conclusion I feel that K2 is going to be a very powerful model, and I look forward to more evaluations from the community. Additionally, Moonshot has been very strong in Vision-Language (VL) and Reinforcement Learning (RL) before, so we can expect that after some more training, a K2-based model for thinking and vision understanding will have a chance to shine!\nAt the same time, as a company with many masters like Su Yin, \u0026ldquo;Jiang Kernel,\u0026rdquo; and Feilaige\u0026rsquo;s own Zhang Yu, Moonshot feels very promising! Moreover, Moonshot not only implements fancy new technologies like Muon but also generously acknowledges and uses advanced technologies from competitors. I feel that shows great character and vision!\nFootnotes The Story of Feilai Pavilion (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan\u0026rsquo;s Muon Blog\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot Muon Paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy Use Muon (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM PR for Muon\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMoonshot K2 Announcement\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM Zero-1 Sharding Scheme Image\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller Jordan defending on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEssential AI critiques Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDion\u0026rsquo;s critique of Moonshot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSeunghyun Seo\u0026rsquo;s critique of Moonshot on X\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP2 Sharding Docs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMegatron-LM bucket implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPyTorch FSDP1 Flat Params\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s early Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHigh-order µP Derivations (Chinese)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDiscussion on X about Muon + µP\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeller\u0026rsquo;s latest Muon implementation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPost on X calling qknorm a \u0026ldquo;band-aid\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/posts/muon-kimi2-translation/","summary":"\u003ch2 id=\"about-the-translation\"\u003eAbout the translation\u003c/h2\u003e\n\u003cp\u003eThis is a translation of the original blog post by toothacher17. The original post is in Chinese and can be found \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehere\u003c/a\u003e. The author\u0026rsquo;s tweet about it is \u003ca href=\"https://x.com/JingyuanLiu123/status/1944071538569097352\"\u003ehere\u003c/a\u003e. I (Jim Robinson-Bohnslav) translated it using Google Translate, Deepseek-R1, Gemini 2.5 Pro, and O3.\u003c/p\u003e\n\u003ch2 id=\"original-post\"\u003eOriginal Post\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor:\u003c/strong\u003e toothacher17\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOriginal Link:\u003c/strong\u003e \u003ca href=\"https://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\"\u003ehttps://www.zhihu.com/question/1927140506573435010/answer/1927378524513219780\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSource:\u003c/strong\u003e Zhihu\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eCopyright belongs to the author. For commercial reprint, please contact the author for authorization. For non-commercial reprint, please indicate the source.\u003c/em\u003e\u003c/p\u003e","title":"Defending Muon: A Deep Dive into Moonshot's K2 Optimizer (A Translated Analysis)"},{"content":"There exists a class of models whose inputs are text prompts + images or video. Their outputs are text.\nExample: \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo; Answer, courtesy of GPT4o:\nThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\nBuilding these models is one of the biggest fields of both industrial AI and academic computer vision research. But no one can agree on what to call them! For the rest of this post I\u0026rsquo;m going to keep calling them \u0026ldquo;these models\u0026rdquo; because I don\u0026rsquo;t know what else to do.\nChoices Multimodal Large Language Models (MLLM)\nThis is probably the most common name for \u0026ldquo;these models\u0026rdquo;. Points in favor: they all use LLMs as a core component. These models generate text, just like LLMs. They are multi-modal, able to process multiple types of inputs.\nThe problem is that this name is not specific enough: imagine a model where you submit an audio file to and ask a question, e.g. \u0026ldquo;What sound is this?\u0026rdquo; + sound.wav -\u0026gt; \u0026ldquo;This is a siren of an emergency vehicle.\u0026rdquo; Such a model would also be an MLLM.\nProponents: vLLM, Llama 31, Pixtral2, Gemini3, Waymo4, Cambrian-15, InternVL2.5 6, Mammoth-VL7, Florence-VL 8, Fei Fei Li (NeurIPS)\nVision-Language Model (VLM)\nVLM is more specific than MLLM, which is good. However, models like CLIP and SigLIP are Vision-Language Models too. They have image encoders, text encoders, can be prompted, etc. But CLIP et al. are not generative; they do not produce text. That makes this term confusing to me.\nProponents: Molmo9, Huggingface (SmolVLM), PaliGemma 2 10, CogVLM11, NVILA12\nLarge Vision-Language Model (LVLM)\n\u0026ldquo;These models\u0026rdquo; are large, use vision, and generate language. Pretty good. But InternViT-6B is a CLIP-style model with 6 billion parameters: it\u0026rsquo;s large by any measure. InternViT isn\u0026rsquo;t generative, so it\u0026rsquo;s not the kind of model I mean. This paper13 even calls CLIP a VLM and \u0026ldquo;these models\u0026rdquo; LVLMs, so I guess generating text is what makes it \u0026ldquo;Large\u0026rdquo;?\nProponents: Qwen2-VL14\nLarge Multimodal Model (LMM)\nThis one is popular with the Llava folks. They get extra credit because their paper defined the field, but I see this as just a variant of MLLM.\nProponents: Llava15, Llava-OneVision16\nMy take I\u0026rsquo;ve been a proponent of calling \u0026ldquo;these models\u0026rdquo; MLLMs. However, models like GPT4o and Gemini Flash 2.0 can consume text, images, video, or audio, and generate text, images, or audio as well. That is truly multimodal. It\u0026rsquo;s such a big difference that the GPT4o system card17 calls it an \u0026ldquo;omni model\u0026rdquo;.\nModels focusing on images and videos specifically are going to be extremely valuable in many domains: robotics, web agents, as components in coding assistants, and in consumer apps. It therefore makes sense to define them as a class distinctly from the \u0026ldquo;omni models.\u0026rdquo;\nThrough writing this post, I\u0026rsquo;ve convinced myself that VLM is a more specific, useful term. With great apologies to Lucas Beyer and the rest of the SigLIP team, I will call models that learn a joint embedding space between images and text \u0026ldquo;CLIP-style models.\u0026rdquo;\nWhat do you think we should call VLMs? Let\u0026rsquo;s discuss on Twitter or BlueSky.\nReferences A. Dubey et al., \u0026ldquo;The Llama 3 Herd of Models,\u0026rdquo; Jul. 31, 2024, arXiv: arXiv:2407.21783. Accessed: Aug. 01, 2024. [Online]. Available: http://arxiv.org/abs/2407.21783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Agrawal et al., \u0026ldquo;Pixtral 12B,\u0026rdquo; Oct. 09, 2024, arXiv: arXiv:2410.07073. Accessed: Oct. 10, 2024. [Online]. Available: http://arxiv.org/abs/2410.07073\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nG. Team et al., \u0026ldquo;Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\u0026rdquo; Aug. 08, 2024, arXiv: arXiv:2403.05530. doi: 10.48550/arXiv.2403.05530.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ.-J. Hwang et al., \u0026ldquo;EMMA: End-to-End Multimodal Model for Autonomous Driving,\u0026rdquo; Oct. 30, 2024, arXiv: arXiv:2410.23262. Accessed: Nov. 04, 2024. [Online]. Available: http://arxiv.org/abs/2410.23262\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nS. Tong et al., \u0026ldquo;Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs,\u0026rdquo; Jun. 24, 2024, arXiv: arXiv:2406.16860. Accessed: Jun. 25, 2024. [Online]. Available: http://arxiv.org/abs/2406.16860\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Chen et al., \u0026ldquo;Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05271. doi: 10.48550/arXiv.2412.05271.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Guo et al., \u0026ldquo;MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,\u0026rdquo; Dec. 06, 2024, arXiv: arXiv:2412.05237. doi: 10.48550/arXiv.2412.05237.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJ. Chen et al., \u0026ldquo;Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04424. doi: 10.48550/arXiv.2412.04424.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM. Deitke et al., \u0026ldquo;Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models,\u0026rdquo; Sep. 25, 2024, arXiv: arXiv:2409.17146. Accessed: Sep. 26, 2024. [Online]. Available: http://arxiv.org/abs/2409.17146\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA. Steiner et al., \u0026ldquo;PaliGemma 2: A Family of Versatile VLMs for Transfer,\u0026rdquo; Dec. 04, 2024, arXiv: arXiv:2412.03555. doi: 10.48550/arXiv.2412.03555.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nW. Hong et al., \u0026ldquo;CogVLM2: Visual Language Models for Image and Video Understanding,\u0026rdquo; Aug. 29, 2024, arXiv: arXiv:2408.16500. Accessed: Aug. 30, 2024. [Online]. Available: http://arxiv.org/abs/2408.16500\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nZ. Liu et al., \u0026ldquo;NVILA: Efficient Frontier Visual Language Models,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04468. doi: 10.48550/arXiv.2412.04468.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nY. Ouali et al., \u0026ldquo;Discriminative Fine-tuning of LVLMs,\u0026rdquo; Dec. 05, 2024, arXiv: arXiv:2412.04378. doi: 10.48550/arXiv.2412.04378.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nP. Wang et al., \u0026ldquo;Qwen2-VL: Enhancing Vision-Language Model\u0026rsquo;s Perception of the World at Any Resolution,\u0026rdquo; Sep. 18, 2024, arXiv: arXiv:2409.12191. Accessed: Sep. 19, 2024. [Online]. Available: http://arxiv.org/abs/2409.12191\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nH. Liu, C. Li, Q. Wu, and Y. J. Lee, \u0026ldquo;Visual Instruction Tuning,\u0026rdquo; Dec. 11, 2023, arXiv: arXiv:2304.08485. Accessed: Jun. 28, 2024. [Online]. Available: http://arxiv.org/abs/2304.08485\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nB. Li et al., \u0026ldquo;LLaVA-OneVision: Easy Visual Task Transfer,\u0026rdquo; Aug. 06, 2024, arXiv: arXiv:2408.03326. Accessed: Aug. 07, 2024. [Online]. Available: http://arxiv.org/abs/2408.03326\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026#160;\u0026#x21a9;\u0026#xfe0e; ","permalink":"http://localhost:1313/posts/mllms/","summary":"\u003cp\u003eThere exists a class of models whose \u003cem\u003einputs are text prompts + images or video. Their outputs are text.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eExample:  \u0026ldquo;Explain the joke in this tweet. Be concise.\u0026rdquo;\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/images/server-joke.webp\"\n         alt=\"home-server-joke\" width=\"600\"/\u003e \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eAnswer, courtesy of GPT4o:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe joke humorously compares \u0026ldquo;the talk\u0026rdquo; about sensitive topics with explaining to kids why there\u0026rsquo;s a server at home. The mock children\u0026rsquo;s book title exaggerates the idea, poking fun at tech enthusiasts whose home servers are significant enough to require a formal explanation to their kids.\u003c/p\u003e","title":"MLLMs, VLMs, LVLMs, LMMs..."},{"content":"\nI’m a machine learning engineer at Zoox, training and shipping foundation models for robotic perception.\nPreviously, I worked at Cobot as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented initial prototypes.\nPrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\nIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\nFind me online Twitter/X Bluesky LinkedIn GitHub Google Scholar ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cimg alt=\"Profile picture\" loading=\"lazy\" src=\"/images/Jim_Green.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eI’m a machine learning engineer at \u003ca href=\"https://www.zoox.com\"\u003eZoox\u003c/a\u003e, training and shipping foundation models for robotic perception.\u003c/p\u003e\n\u003cp\u003ePreviously, I worked at \u003ca href=\"http://www.co.bot\"\u003eCobot\u003c/a\u003e as the first perception hire and second SWE. I did zero-to-one prototyping, evaluated sensor suites, designed the perception system, and implemented  initial prototypes.\u003c/p\u003e\n\u003cp\u003ePrior to that, I was a research scientist at Perceptive Automata, training models to help AVs understand human behavior.\u003c/p\u003e\n\u003cp\u003eIn my academic life, I did my PhD in Neuroscience at Harvard, building novel computer vision pipelines for analyzing animal behavior in Chris Harvey’s lab.\u003c/p\u003e","title":"About"}]